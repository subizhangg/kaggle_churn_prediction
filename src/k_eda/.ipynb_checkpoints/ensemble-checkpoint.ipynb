{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaih/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/kaih/.local/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/home/kaih/.local/lib/python3.5/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import glob\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import gc; gc.enable()\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../../data/raw/train.csv')\n",
    "test = pd.read_csv('../../../data/raw/sample_submission_zero.csv')\n",
    "members = pd.read_csv('../../../data/raw/members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggtrain = pd.read_csv('../../results/aggtrain.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggtest = pd.read_csv('../../results/aggtest.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(970960, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(970960, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# aggtrain =aggtrain.fillna(0)\n",
    "# aggtest=aggtest.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_features = [\n",
    "    'bd',\n",
    "                       'avg(payment_plan_days)',\n",
    "                       'avg(plan_list_price)',\n",
    "                       'avg(actual_amount_paid)',\n",
    "                       'max(num_100)',\n",
    "                       'max(num_25)',\n",
    "                       'max(num_75)',\n",
    "                       'max(num_unq)',\n",
    "                       'max(num_50)',\n",
    "                       'max(num_985)',\n",
    "                       'max(total_secs)',\n",
    "        'count(transaction_date)', # num transactions\n",
    "    'count(date)' # num logs\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'city',\n",
    "                       'gender',\n",
    "                       'registered_via',\n",
    "#                        '_c0',\n",
    "                       'max(is_cancel)',\n",
    "                       'min(is_auto_renew)'\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "le = LabelEncoder()\n",
    "for i in categorical_features:\n",
    "    aggtrain[i] = le.fit_transform(aggtrain[i].apply(str).values)\n",
    "    aggtest[i] = le.fit_transform(aggtest[i].apply(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = aggtrain[categorical_features+continuous_features]\n",
    "Xtest = aggtest[categorical_features+continuous_features]\n",
    "y = aggtrain.is_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "def xgb_score(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'log_loss', log_loss(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-log_loss:0.676522\tvalid-log_loss:0.676525\n",
      "Multiple eval metrics have been passed: 'valid-log_loss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-log_loss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-log_loss:0.280326\tvalid-log_loss:0.280625\n",
      "[100]\ttrain-log_loss:0.17681\tvalid-log_loss:0.177481\n"
     ]
    }
   ],
   "source": [
    "fold = 1\n",
    "round = 0\n",
    "for i in np.random.randint(1,1000,fold):\n",
    "\n",
    "    params = {\n",
    "        'eta': 0.02,\n",
    "#         'learning_rate': 0.05, # use smaller learning rate to prevent overfit?\n",
    "        'gamma': 10,\n",
    "        'max_depth': 7,\n",
    "        'n_estimators': 200,\n",
    "        #'random_state': 850564,\n",
    "#         'min_child_weight': 2,\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'seed': i,\n",
    "        'silent': True,\n",
    "    }\n",
    "    x1, x2, y1, y2 = train_test_split(Xtrain, y, test_size=0.33, random_state=i)\n",
    "    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "    model = xgb.train(params, xgb.DMatrix(x1, y1), 150,  watchlist, feval=xgb_score, maximize=False, verbose_eval=50, early_stopping_rounds=50)\n",
    "    if round != 0:\n",
    "        pred += model.predict(xgb.DMatrix(Xtest), ntree_limit=model.best_ntree_limit)\n",
    "    else:\n",
    "        pred = model.predict(xgb.DMatrix(Xtest), ntree_limit=model.best_ntree_limit)\n",
    "    round += 1\n",
    "pred /= fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "xgbprediction=aggtest[['msno','is_churn']]\n",
    "xgbprediction['is_churn'] = pred.clip(0.0000001, 0.999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgbprediction.to_csv('../../results/xgbsubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggtrain_enc = aggtrain[categorical_features+continuous_features+['is_churn']]\n",
    "aggtest_enc = aggtest[categorical_features+continuous_features+['is_churn']]\n",
    "aggtrain_enc =aggtrain_enc.fillna(-1)\n",
    "aggtest_enc=aggtest_enc.fillna(-1)\n",
    "for i in categorical_features:\n",
    "    aggtrain_enc[i] = aggtrain[i].astype('category')\n",
    "    aggtest_enc[i] = aggtest[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "aggtrain_enc = pd.get_dummies(aggtrain_enc)\n",
    "aggtest_enc = pd.get_dummies(aggtest_enc)\n",
    "\n",
    "Xtrain_enc = aggtrain_enc.loc[:, aggtrain_enc.columns != 'is_churn']\n",
    "Xtest_enc = aggtest_enc.loc[:, aggtest_enc.columns != 'is_churn']\n",
    "# y = np.asarray(aggtrain_enc['is_churn'], dtype=\"float64\")\n",
    "y = aggtrain.is_churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest_enc=Xtest_enc.loc[:, Xtest_enc.columns != 'max(is_cancel)_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest_enc=Xtest_enc.loc[:, Xtest_enc.columns != 'min(is_auto_renew)_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(Xtrain_enc,y)\n",
    "lrpred = lr.predict(Xtest_enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "lrprediction=aggtest[['msno','is_churn']]\n",
    "lrprediction['is_churn'] = lrpred.clip(0.0000001, 0.999999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.fit(Xtrain_enc,y)\n",
    "rfpred=rf.predict(Xtest_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rfprediction=aggtest[['msno','is_churn']]\n",
    "rfprediction['is_churn'] = rfpred.clip(0.0000001, 0.999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfprediction.to_csv('../../results/rfsubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = xgbprediction.merge(rfprediction,on='msno')\n",
    "# prediction['is_churn'] = (prediction['is_churn_x']+prediction['is_churn_y']+prediction['is_churn'])/3\n",
    "prediction['is_churn'] = (prediction['is_churn_x']+prediction['is_churn_y'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = prediction[['msno','is_churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction.to_csv('../../results/rfxgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = xgbprediction.merge(rfprediction,on='msno')\n",
    "prediction = prediction.merge(lrprediction,on='msno')\n",
    "prediction['is_churn'] = (prediction['is_churn_x']+prediction['is_churn_y']+prediction['is_churn'])/3\n",
    "prediction = prediction[['msno','is_churn']]\n",
    "prediction.to_csv('../../results/lrrfxgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR (no parallelism.. very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "\n",
    "# svr = SVR()\n",
    "# svr.fit(Xtrain_enc,y)\n",
    "# rfpred=svr.predict(Xtest_enc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "very.... ssssllloooooooooooowww...... like, I've been running it for over 40 hours and it just won't stop kinda slow.. don't try this. Training complexity of nonlinear SVM is generally between O(n^2) and O(n^3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load trained randomforest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '../../models/rf_depth5nest100leaf1.sav'\n",
    "rf_load = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfpred=rf_load.predict(Xtest_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
